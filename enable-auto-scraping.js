#!/usr/bin/env node
/**
 * Enable Auto-Scraping System
 * Starts the automated job scraping with schedule
 */

const JobScheduler = require('./services/jobScheduler');

async function enableAutoScraping() {
    console.log('ðŸ¤– Enabling Automated Job Scraping System');
    console.log('==========================================\n');

    try {
        // Set environment variable
        process.env.ENABLE_AUTO_SCRAPING = 'true';
        
        console.log('âœ… Environment variable set: ENABLE_AUTO_SCRAPING=true');
        
        // Initialize scheduler
        const scheduler = new JobScheduler();
        console.log('âœ… Job scheduler initialized');
        
        // Start the automated scheduling
        scheduler.startScheduler();
        console.log('âœ… Automated scraping started!');
        
        console.log('\nðŸ“… Scraping Schedule:');
        console.log('â€¢ Every 2 hours: Quick scrape for new jobs');
        console.log('â€¢ Daily at 6 AM: Comprehensive scrape across all sources');
        console.log('â€¢ Sources: Indeed, LinkedIn, Craigslist, Google Jobs');
        
        console.log('\nðŸŽ¯ Job Targeting:');
        console.log('â€¢ Entry-level positions');
        console.log('â€¢ College student opportunities');
        console.log('â€¢ Recent graduate roles');
        console.log('â€¢ Internships and trainee positions');
        
        // Run an immediate scrape to test
        console.log('\nðŸš€ Running initial scrape test...');
        const result = await scheduler.runScraping();
        
        console.log('âœ… Initial scrape completed!');
        console.log(`ðŸ“Š Results: ${result.newJobs} new jobs added (${result.totalJobs} total)`);
        
        console.log('\nðŸŽ‰ Automated Job Scraping is now ACTIVE!');
        console.log('\nðŸ“± Monitor with these endpoints:');
        console.log('â€¢ GET /api/scraping/stats - View scraping statistics');
        console.log('â€¢ GET /api/fresh - Get fresh scraped jobs');
        console.log('â€¢ POST /api/scrape-now - Manual scraping trigger');
        
        console.log('\nðŸš€ For Railway deployment, set this environment variable:');
        console.log('ENABLE_AUTO_SCRAPING=true');
        
        // Keep the process running
        console.log('\nâ° System will continue running and scraping automatically...');
        console.log('Press Ctrl+C to stop the auto-scraping system');
        
        // Keep process alive
        setInterval(() => {
            const stats = scheduler.getScrapingStats();
            console.log(`\nðŸ“Š [${new Date().toLocaleTimeString()}] Scraping Stats:`, {
                lastRun: stats.lastSuccessfulScrape || 'Never',
                totalRuns: stats.totalRuns || 0,
                jobsToday: stats.jobsScrapedToday || 0
            });
        }, 300000); // Every 5 minutes
        
    } catch (error) {
        console.error('âŒ Error enabling auto-scraping:', error.message);
        console.error('\nðŸ’¡ Troubleshooting:');
        console.error('1. Make sure all dependencies are installed: npm install');
        console.error('2. Check that services/jobScheduler.js exists');
        console.error('3. Verify data directory has write permissions');
    }
}

// Handle graceful shutdown
process.on('SIGINT', () => {
    console.log('\n\nðŸ›‘ Stopping automated job scraping...');
    console.log('âœ… Auto-scraping disabled. Restart with this script to re-enable.');
    process.exit(0);
});

// Run the auto-scraping enabler
if (require.main === module) {
    enableAutoScraping().catch(error => {
        console.error('ðŸ’¥ Failed to enable auto-scraping:', error);
        process.exit(1);
    });
}

module.exports = enableAutoScraping;
